{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNSP55rZzYt+2PxbHQ8ULrB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AUvtycnNFwcy"},"outputs":[],"source":["# Core dependencies\n","pip install PyPDF2  # For PDF processing\n","pip install pandas  # For data manipulation\n","pip install openai  # For OpenAI API integration\n","pip install networkx  # For graph operations\n","pip install chromadb  # Vector database\n","pip install langchain  # For document processing and embeddings\n","pip install scikit-learn  # For machine learning utilities\n","pip install nltk  # For natural language processing\n","pip install sentence-transformers  # For text embeddings\n","pip install tqdm  # For progress bars\n","pip install langchain-community  # For OpenAI embeddings\n","\n","pip install \"PyPDF2>=3.0.0\"\n","pip install \"langchain>=0.1.0\"\n","pip install \"chromadb>=0.3.0\"\n","pip install \"sentence-transformers>=2.2.0\"\n"]},{"cell_type":"code","source":["import os\n","import json\n","import logging\n","import PyPDF2\n","import pandas as pd\n","import openai  # OpenAI API for text completions\n","import networkx as nx\n","from typing import List, Dict, Optional, Tuple\n","from pathlib import Path\n","import time\n","from uuid import uuid4\n","import chromadb\n","from langchain.vectorstores import Chroma\n","from langchain.docstore.document import Document\n","import re\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","from collections import defaultdict\n","from datetime import datetime\n","from sklearn.cluster import KMeans\n","from nltk.tokenize import sent_tokenize\n","from sentence_transformers import SentenceTransformer\n","from tqdm import tqdm\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","import nltk\n","nltk.download('punkt')\n","\n","# Configure logging\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    handlers=[\n","        logging.FileHandler('audit_analysis.log'),\n","        logging.StreamHandler()\n","    ]\n",")\n","logger = logging.getLogger(__name__)\n","\n","# Constants\n","CHROMA_PATH = \"./chroma_vectordb_openAI1207\"  # Update to your preferred path\n","MAX_RETRIES = 3\n","RETRY_DELAY = 1\n","MAX_CONTEXT_LENGTH = 15000\n","CHUNK_SIZE = 1000\n","SIMILARITY_THRESHOLD = 0.7\n","SEMANTIC_WEIGHT = 0.8\n","SEQUENTIAL_WEIGHT = 0.6\n","\n","# Replace with your actual OpenAI API key\n","from openai import OpenAI\n","from langchain_community.embeddings import OpenAIEmbeddings\n","\n","# Your API key\n","api_key = \"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\"\n","\n","# Method 1: Set the environment variable correctly\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = api_key  # \"OPENAI_API_KEY\" is the required name\n","embeddings = OpenAIEmbeddings()\n","\n","\n","\n","PROMPT_TEMPLATE = \"\"\"\n","# CONTEXT\n","You are given a question from an audit inspection and the relevant content related to that question. Your task is to analyze the content to summarize the findings, provide a clear conclusion, and deliver a one-word result based on the audit's compliance with the question.\n","Question: {question}\n","Content: {content}\n","\n","# OBJECTIVE\n","Analyze the provided context (question and related content) and return four outputs:\n","\n","Findings: Summarize the relevant sections and subsections from the content.\n","Conclusion: Provide a full-sentence conclusion based on the findings that directly answers the question.\n","Result: Give a one-word result based on the conclusion: Pass, Fail, NA (Not Applicable), or Uncertain.\n","Confidence_Perc: Provide a confidence score (out of 100) that reflects the certainty of the conclusion.\n","\n","# RESPONSE FORMAT\n","Return your analysis in JSON format with the following structure:\n","{{\n","    \"findings\": \"Your summary of findings here\",\n","    \"conclusion\": \"Your conclusion here\",\n","    \"result\": \"Pass/Fail/NA/Uncertain\",\n","    \"confidence\": number\n","}}\n","\"\"\"\n","\n","# Semantic chunking function\n","\n","def setup_nltk():\n","    \"\"\"\n","    Set up NLTK by downloading required resources.\n","    \"\"\"\n","    try:\n","        import nltk\n","        nltk.download('punkt', quiet=True)\n","        nltk.download('punkt_tab', quiet=True)\n","        return True\n","    except Exception as e:\n","        logger.warning(f\"NLTK setup failed: {e}\")\n","        return False\n","\n","def simple_sentence_split(text: str) -> List[str]:\n","    \"\"\"\n","    Simple sentence splitting fallback method.\n","    \"\"\"\n","    # Split on common sentence endings\n","    sentences = []\n","    current = \"\"\n","\n","    # Add space after common sentence endings if missing\n","    text = text.replace('.',' . ').replace('!',' ! ').replace('?',' ? ')\n","    text = ' '.join(text.split())  # Normalize spaces\n","\n","    for word in text.split():\n","        current += word + \" \"\n","        if word in ['.', '!', '?']:\n","            current = current.strip()\n","            if current:\n","                sentences.append(current)\n","            current = \"\"\n","\n","    if current.strip():\n","        sentences.append(current.strip())\n","\n","    return sentences or [text]\n","\n","def semantic_chunk(text: str, sentence_model, max_chunk_size: int = 750, min_chunk_size: int = 200) -> List[str]:\n","    try:\n","        sentences = sent_tokenize(text)\n","        if not sentences:\n","            return [text] if text.strip() else []\n","\n","        # Remove empty sentences and normalize whitespace\n","        sentences = [s.strip() for s in sentences if s.strip()]\n","        embeddings = sentence_model.encode(sentences)\n","        text_length = sum(len(s) for s in sentences)\n","        num_clusters = max(1, text_length // max_chunk_size)\n","\n","        kmeans = KMeans(n_clusters=min(num_clusters, len(sentences)), random_state=42)\n","        clusters = kmeans.fit_predict(embeddings)\n","\n","        grouped_sentences = defaultdict(list)\n","        for sentence, cluster in zip(sentences, clusters):\n","            grouped_sentences[cluster].append(sentence)\n","\n","        chunks = []\n","        for cluster_sentences in grouped_sentences.values():\n","            chunks.append(' '.join(cluster_sentences))\n","        return chunks\n","\n","    except Exception as e:\n","        logger.error(f\"Error in semantic chunking: {e}\")\n","        return [text] if text.strip() else []\n","\n","class DocumentProcessor:\n","    def load_pdf(self, pdf_path: str) -> List[str]:\n","        try:\n","            with open(pdf_path, \"rb\") as file:\n","                reader = PyPDF2.PdfReader(file)\n","                pages = [page.extract_text() for page in reader.pages if page.extract_text()]\n","            return pages\n","        except Exception as e:\n","            logger.error(f\"Failed to load PDF {pdf_path}: {e}\")\n","            return []\n","\n","\n","\n","\n","\n","    def process_pages(self, pages: List[str], sentence_model) -> List[str]:\n","        all_chunks = []\n","        for page in pages:\n","            chunks = semantic_chunk(page, sentence_model)\n","            all_chunks.extend(chunks)\n","        return all_chunks\n","\n","# KnowledgeNode and KnowledgeGraph Classes\n","class KnowledgeNode:\n","    def __init__(self, node_id, text, embedding):\n","        self.node_id = node_id\n","        self.text = text\n","        self.embedding = embedding\n","\n","class KnowledgeGraph:\n","    def __init__(self):\n","        self.graph = nx.Graph()\n","\n","    def add_node(self, node: KnowledgeNode):\n","        self.graph.add_node(node.node_id, text=node.text, embedding=node.embedding)\n","\n","    def add_edge(self, node1_id, node2_id, relation, weight):\n","        self.graph.add_edge(node1_id, node2_id, relation=relation, weight=weight)\n","\n","    def get_statistics(self):\n","        return {\n","            \"total_nodes\": self.graph.number_of_nodes(),\n","            \"total_edges\": self.graph.number_of_edges()\n","        }\n","\n","    def get_subgraph(self, node_ids, depth=1):\n","        subgraph_nodes = set(node_ids)\n","        for node_id in node_ids:\n","            neighbors = nx.single_source_shortest_path_length(self.graph, node_id, cutoff=depth)\n","            subgraph_nodes.update(neighbors.keys())\n","        return self.graph.subgraph(subgraph_nodes)\n","\n","    def get_node_text(self, node_id):\n","        return self.graph.nodes[node_id][\"text\"] if node_id in self.graph.nodes else None\n","\n","\n","\n","\n","\n","\n","class EnhancedAuditAnalyzer:\n","\n","    def __init__(self):\n","        self.vector_store = None\n","        self.knowledge_graph = KnowledgeGraph()\n","        self.document_processor = DocumentProcessor()\n","        self.embeddings = embeddings  # Store the embeddings instance\n","\n","    def setup_environment(self):\n","        try:\n","            # Set up the OpenAI API key\n","            os.environ[\"OPENAI_API_KEY\"] = api_key\n","            logger.info(\"Environment setup completed successfully\")\n","            return True\n","        except Exception as e:\n","            logger.error(f\"Environment setup failed: {e}\")\n","            raise\n","\n","    def process_document(self, pdf_path: str, sentence_model) -> List[str]:\n","        pages = self.document_processor.load_pdf(pdf_path)\n","        if not pages:\n","            return []\n","        return self.document_processor.process_pages(pages, sentence_model)\n","\n","    def build_knowledge_base(self, chunks: List[str], source: str):\n","        documents = []\n","        embeddings_list = []\n","\n","        try:\n","            for i, chunk in enumerate(chunks):\n","                embedding = self.embeddings.embed_query(chunk)\n","                embeddings_list.append((chunk, embedding))\n","                doc = Document(page_content=chunk, metadata={\"source\": source, \"chunk_index\": i})\n","                documents.append(doc)\n","                node = KnowledgeNode(i, chunk, embedding)\n","                self.knowledge_graph.add_node(node)\n","\n","            if documents:\n","                self.vector_store = Chroma.from_documents(\n","                    documents,\n","                    embedding=self.embeddings,\n","                    persist_directory=CHROMA_PATH\n","                )\n","            else:\n","                logger.error(\"No valid documents were created, skipping vector store creation.\")\n","\n","            self._build_graph_edges_with_precomputed_embeddings(embeddings_list)\n","\n","        except Exception as e:\n","            logger.error(f\"Error building knowledge base: {e}\")\n","            raise\n","\n","    def _build_graph_edges_with_precomputed_embeddings(self, embeddings: List[Tuple[str, np.ndarray]]):\n","        try:\n","            for i in range(len(embeddings)):\n","                for j in range(i + 1, len(embeddings)):\n","                    try:\n","                        similarity = cosine_similarity(\n","                            [embeddings[i][1]], [embeddings[j][1]]\n","                        )[0][0]\n","                        if similarity > SIMILARITY_THRESHOLD:\n","                            self.knowledge_graph.add_edge(\n","                                i, j, \"semantic_similarity\",\n","                                similarity * SEMANTIC_WEIGHT\n","                            )\n","                        if j == i + 1:\n","                            self.knowledge_graph.add_edge(\n","                                i, j, \"sequential\", SEQUENTIAL_WEIGHT\n","                            )\n","                    except Exception as e:\n","                        logger.error(f\"Error building edge between chunks {i} and {j}: {e}\")\n","                        continue\n","            logger.info(\"Graph edges successfully built.\")\n","        except Exception as e:\n","            logger.error(f\"Error in _build_graph_edges: {e}\")\n","            raise\n","\n","    def get_relevant_context(self, query: str) -> str:\n","        if not self.vector_store:\n","            return \"\"\n","        results = self.vector_store.similarity_search(query, k=3)\n","        return \"\\n\\n\".join(doc.page_content for doc in results)\n","\n","    def analyze_query(self, query: str) -> Dict:\n","        \"\"\"\n","        Analyze a query using the knowledge base.\n","\n","        Args:\n","            query: The query string to analyze\n","\n","        Returns:\n","            Dict containing findings, conclusion, result, and confidence\n","        \"\"\"\n","        try:\n","            context = self.get_relevant_context(query)\n","            if not context:\n","                return {\n","                    \"findings\": \"No relevant context found\",\n","                    \"conclusion\": \"Uncertain\",\n","                    \"result\": \"Uncertain\",\n","                    \"confidence\": 0\n","                }\n","\n","            # Create OpenAI client instance\n","            client = OpenAI()\n","\n","            # Use the Chat Completion API with proper client instantiation\n","            response = client.chat.completions.create(\n","                model=\"gpt-4o-mini\",\n","                messages=[\n","                    {\n","                        \"role\": \"system\",\n","                        \"content\": \"You are an audit analysis assistant that provides structured responses in JSON format.\"\n","                    },\n","                    {\n","                        \"role\": \"user\",\n","                        \"content\": PROMPT_TEMPLATE.format(question=query, content=context)\n","                    }\n","                ],\n","                temperature=0\n","            )\n","\n","            if response and response.choices:\n","                response_text = response.choices[0].message.content.strip()\n","                return self._parse_response(response_text)\n","\n","            return {\n","                \"findings\": \"No response received from OpenAI API\",\n","                \"conclusion\": \"Uncertain\",\n","                \"result\": \"Uncertain\",\n","                \"confidence\": 0\n","            }\n","\n","        except Exception as e:\n","            logger.error(f\"Error in analyze_query: {e}\")\n","            return {\n","                \"findings\": f\"Error: {str(e)}\",\n","                \"conclusion\": \"Uncertain\",\n","                \"result\": \"Uncertain\",\n","                \"confidence\": 0\n","            }\n","\n","    def _parse_response(self, response_text: str) -> Dict:\n","        try:\n","            clean_text = response_text.strip()\n","            json_match = re.search(r'(\\{[\\s\\S]*\\})', clean_text)\n","            if not json_match:\n","                logger.warning(\"No JSON found in response\")\n","                return {\n","                    \"findings\": clean_text[:500],\n","                    \"conclusion\": \"Error parsing response\",\n","                    \"result\": \"Uncertain\",\n","                    \"confidence\": 0\n","                }\n","            result = json.loads(json_match.group(1))\n","            required_fields = {'findings', 'conclusion', 'result', 'confidence'}\n","            if not all(field in result for field in required_fields):\n","                missing_fields = required_fields - set(result.keys())\n","                logger.warning(f\"Missing required fields in response: {missing_fields}\")\n","                return {\n","                    \"findings\": \"Missing required fields in response\",\n","                    \"conclusion\": \"Error parsing response\",\n","                    \"result\": \"Uncertain\",\n","                    \"confidence\": 0\n","                }\n","            valid_results = {'Pass', 'Fail', 'NA', 'Uncertain'}\n","            if result['result'] not in valid_results:\n","                logger.warning(f\"Invalid result value: {result['result']}\")\n","                result['result'] = 'Uncertain'\n","            try:\n","                confidence = float(result['confidence'])\n","                result['confidence'] = max(0, min(100, confidence))\n","            except (ValueError, TypeError):\n","                logger.warning(\"Invalid confidence value\")\n","                result['confidence'] = 0\n","            return result\n","        except Exception as e:\n","            logger.error(f\"Error parsing response: {e}\")\n","            return {\n","                \"findings\": response_text[:500],\n","                \"conclusion\": \"Error parsing response\",\n","                \"result\": \"Uncertain\",\n","                \"confidence\": 0\n","            }\n","\n","\n","class AuditAnalysisRunner:\n","    def __init__(self, pdf_path: str, questions_path: str, output_path: str = None):\n","        self.pdf_path = pdf_path\n","        self.questions_path = questions_path\n","        self.output_path = output_path or f\"audit_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n","        self.analyzer = None\n","        self.sentence_model = None\n","\n","    def setup(self):\n","        self.sentence_model = SentenceTransformer('multi-qa-mpnet-base-cos-v1')\n","        self.analyzer = EnhancedAuditAnalyzer()\n","\n","\n","    def load_questions(self) -> List[Dict]:\n","        df = pd.read_csv(self.questions_path)\n","        return df.to_dict('records')\n","\n","    def process_document(self):\n","        chunks = self.analyzer.process_document(self.pdf_path, self.sentence_model)\n","        self.analyzer.build_knowledge_base(chunks, self.pdf_path)\n","\n","    def run_analysis(self):\n","        questions = self.load_questions()\n","        results = []\n","        for question in tqdm(questions, desc=\"Analyzing questions\"):\n","            result = self.analyzer.analyze_query(question['Question'])\n","            results.append({\n","                'Question': question['Question'],\n","                'Findings': result['findings'],\n","                'Conclusion': result['conclusion'],\n","                'Result': result['result'],\n","                'Confidence': result['confidence']\n","            })\n","        df = pd.DataFrame(results)\n","        df.to_csv(self.output_path, index=False)\n","\n","    def get_summary_statistics(self):\n","        df = pd.read_csv(self.output_path)\n","        stats = {\n","            'total_questions': len(df),\n","            'results_distribution': df['Result'].value_counts().to_dict(),\n","            'average_confidence': df['Confidence'].mean(),\n","        }\n","        return stats\n","\n","\n","# Main execution function\n","def main():\n","    pdf_path = \"/content/Hong Yan textiles SA  2023.09.27 - QIMA Ethical Audit Report (RCloud) (1).pdf\"\n","    questions_path = \"/content/Question_Bank_New (1).csv\"\n","    output_path = \"audit_results_openai.csv\"\n","\n","    runner = AuditAnalysisRunner(pdf_path, questions_path, output_path)\n","    runner.setup()\n","    runner.process_document()\n","    runner.run_analysis()\n","\n","    stats = runner.get_summary_statistics()\n","    print(json.dumps(stats, indent=2))\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"qOaDSdARGCmz"},"execution_count":null,"outputs":[]}]}